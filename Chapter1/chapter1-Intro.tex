\chapter{Introduction to Improvised Visual Summarizer using Denoising Algorithm}
This chapter will introduce the need for a visual summarizer for presentations and lectures and discuss the broad objectives of the project. Further, a brief methodology along with the constraints of the project are discussed. 
\section[Introduction]{\textbf{Introduction}}
As of today, technology is ubiquitous and has advanced at an unprecedented rate in several sectors of our lives with more than half the world’s population living hand-in-hand with technology. From smart watches to smart phones to smart cities, the embodiment of artificial intelligence in all our day-to-day activities no longer looks like a distant dream. Lectures in classrooms have also advanced to the extent of using smart-boards and smart-classrooms; the developments in jotting down notes in such scenarios has, however, not advanced at the same pace. 

Along with reading and listening, taking notes can tend to become  a passive activity where one doesn't quite register what the speaker is talking about but instead aimlessly writes down as much as they can keep up with. If one's approach to note taking involves trying to write down, word-for-word, just about everything that the teacher says, they will be more involved in getting words on paper than in focusing their attention and asking questions about the points that are important. An effective approach for successful classroom learning is to be an active listener as well as take well-organized and brief, yet explicit, notes; making them complete enough to provide you with an overview of the entire lecture.

In the problem statement being tackled, the target audience includes the attendees of any seminar, presentation or lecture, be it students or the public in general, attending important conferences and talks. More often than not, providing complete undivided attention to the speaker proves to be difficult at these seminars as the attendee may be preoccupied with the objective of jotting down pointers and making notes for future reference. It is during this process that several essentials in the speaker’s delivery are missed out. Keeping this in mind, our project delves into the implementation of an efficient visual summarizer that provides a solution to this problem. 
Be it visual images of PowerPoint slides or handwritten material that is presented in the seminars, our project will provide a smart solution of summarizing the entire presentation and generating an output of the same.

\section[Problem statement]{\textbf{Problem statement}}

The process of taking notes during a presentation or seminar tends to become a passive activity while one tries to listen and actively participate in discussions regarding the topic in question. Hence, there is a requirement to aid attendees of lectures and presentations in the process of recording vital information, in a concise format, dispensed during the addressal.


\section[Objectives]{\textbf{Objectives}}
The objectives of the project are
\begin{enumerate}
\item To develop and train a denoising autoencoder to deblur the input image.
\item To build an object detection model to detect text from the deblurred image.
\item To extract the detected text and summarize it using extractive summarization.
\end{enumerate}

\section[Literature Review]{\textbf{Literature Review}}

Literature review, an integral part of every project, provides insight into how the proposed research is related prior research and demonstrates the originality and relevance of one's research problem as well as justifies the proposed methodology. 

\cite{8627998} discusses the powerful learning ability of deep learning based object detection and its potential to handle occlusion, clutter and low-resolution. Further, it also discusses Convolutional Neural Networks and its advantages over traditional methods -- hidden factors of input data can be extracted, exponentially augmented expressive capability, optimization of relative tasks. It also provides a brief review of salient object detection, face detection and pedestrian detection. Finally it demonstrates a few promising future directions and tasks such as multi-task joint optimization, scale adaptation, cascade networks and 3D object detection.

The traditional optical character recognition technology (OCR) requires the text neat layout and neatness and background clean, and industrial production often fail to meet such standards. \cite{wang2017scene} proposes a new method based on convolution neural network (Faster RCNN) that aims to improve the correctness of text recognition. When compared with the conventional detection method, the correct rate of recognition based on Faster RCNN model can reach 90.4\%, and the correctness rate is 88.9\%. When compared with the traditional OCR, the method proposed in this paper is relatively stable, and the accuracy is relatively high.

\cite{bhat2018cost} is our base paper. The objective of this paper was to enable the users to give their undivided attention to the lecture taking place, without them fretting over the key details, as the audio-visual summarizer will permit the users to always go back and refer to the lecture. The proposed solution included 4 vital steps - integration of Raspberry Pi with camera and microphone, implementing a text detection and extraction model, speech to text conversion using LAS model and summarizing the extracted text from images and audio using Natural Language Toolkit (NLTK).

Autoencoder is very popular neural network for image processing. Denoising autoencoder is an important autoencoder because in some tasks we need a preprocessed image to get less noisy result. The research in \cite{yasenko2020image} describes ways to analyze noisy images and how to reduce that noise. The best result achieved after training is for 186 samples and this process has taken 2185.99 seconds and 95\% of 2048 frames have been denoised in 84.26 seconds. Furthermore, it was established that this method is 3.3 times faster than conventional methods.

\cite{hamad2016detailed} provides a detailed analysis of Optical Character Recognition technology. The objective of OCR is to achieve modification or conversion of any form of text or text-containing documents such as handwritten text, printed or scanned text images, into an editable digital format for deeper and further processing. The challenges faced by OCR are scene complexity, conditions of uneven lighting, skewness (rotation), blurring and degradation, aspect ratios, fonts, multilingual environments. There are various phases of OCR such as preprocessing, segmentation, normalization, feature extraction, classification and post processing. Finally, this paper discusses the applications of OCR, namely handwriting recognition, receipt imaging, legal industry, banking, healthcare, automatic number plate recognition, etc.

The objective of \cite{reddy2012efficient} is a summarization system that produces a summary for a given web document based on sentence importance measures. It is an efficient approach for single document summarization which uses the two sentence importance measures. The first is the frequency of the terms in the sentence and its similarity to the other sentences. The second is sentences are ranked according to their respective scores and the sentences with top ranks are selected for summary. The summary is evaluated by using ‘recall’ evaluation measure.

\cite{jiao2019survey} primarily deals with the trends and vast range of research areas of deep-learning based object detection. Some of these trends are as combining one stage (fast but lower accuracy) and two stage detectors (higher accuracy but time consuming), video object detection include obstacles like motion blur, motion target ambiguity, smart targets, etc., versatility of multi-domain object detection. This paper also discusses unsupervised object detection models for intelligent detection mission and advanced medical biometrics to analyze retinal images and speech patterns.
    


\section[Brief Methodology of the project]{\textbf{Brief Methodology of the project}}
Our first step is to train a denoising autoencoder for deblurring the input images. We then move on to prepare an image dataset for training the object detection model, \acrlong{rcn} (Region Based Convolutional Neural Networks). Running the image through a Convoluted Neural Network (CNN) will generate a Feature Map. On running the Activation Map through a separate network, called the Region Proposal Network (RPN), interesting boxes/regions will be generated as outputs. The predicted region proposals are then reshaped using a Region of Interest Pooling (RoIP) layer following which it is passed through R--CNN. R--CNN has two functions:
\begin{enumerate}
\item Classify proposals into one of the classes
\item Better adjust the bounding box for the proposal according to the predicted class i.e. group proposals of similar class to get final bounding box.
\end{enumerate}
Passing the blurred images through a denoising autoencoder before passing through the object detection model will help us achieve accurate detection of the text from the image which we will then extract using Tesseract \acrshort{ocv} module and summarize using Natural Language Toolkit. 

\section[Assumptions made / Constraints of the project]{\textbf{Assumptions made / Constraints of the project}}

The assumptions made for the execution of the project are as follows: 
\begin{enumerate}
    \item \textbf{Hardware Constraint: }Accuracy of the project is impacted due to the lack of GPU and limited RAM.
    \item \textbf{Limited dataset: }The data set prepared is self-made and we were able to collect a limited number of images. With an increased number of images in the dataset will lead to better accuracy.
    \item \textbf{Limitation with respect to blur: }The Denoising Autoencoder is trained for Gaussian blur. For normal blurring, such as that taken from a camera, the output of the autoencoder will not be inaccurate.
\end{enumerate}

\section[Organization of the report]{\textbf{Organization of the report}}

This report is organized as follows. Write the discussions in each chapter. A sample is as follows.
\begin{itemize}
\item Chapter 2 discusses the fundamentals of Convolutional Neural Networks.
\item Chapter 3 introduces object detection and discusses the Faster R–CNN model used as well as the model summary.
\item Chapter 4 introduces the Denoising Autoencoder and gives a description of our model summary and training details.
\item Chapter 5 gives a description of text extraction and summarization methods.
\item Chapter 6 discusses the results obtained after each stage and its analysis.
\item Chapter 7 concludes the report.
\end{itemize}
